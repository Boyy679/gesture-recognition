{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.keras as keras\n",
    "import pandas as pd\n",
    "from tensorflow.contrib.keras.api.keras.callbacks import ReduceLROnPlateau\n",
    "# Load in our data from CSV files\n",
    "train_df = pd.read_csv(\"asl_data/sign_mnist_train.csv\")\n",
    "valid_df = pd.read_csv(\"asl_data/sign_mnist_valid.csv\")\n",
    "\n",
    "# Separate out our target values\n",
    "y_train = train_df['label']\n",
    "y_valid = valid_df['label']\n",
    "del train_df['label']\n",
    "del valid_df['label']\n",
    "\n",
    "# Separate out our image vectors\n",
    "x_train = train_df.values\n",
    "x_valid = valid_df.values\n",
    "\n",
    "# Turn our scalar targets into binary categories\n",
    "num_classes = 24\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
    "\n",
    "# Normalize our image data\n",
    "x_train = x_train / 255\n",
    "x_valid = x_valid / 255"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping Images for a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27455, 784), (7172, 784))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape our dataset so that they are in a 28x28 pixel format.   This will allow our convolutions to associate groups of pixels and detect important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_valid = x_valid.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27455, 28, 28, 1)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7172, 28, 28, 1)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27455, 28, 28, 1), (7172, 28, 28, 1))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Convolutional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_97 (Conv2D)           (None, 28, 28, 100)       1000      \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 28, 28, 100)       400       \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 28, 28, 75)        67575     \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 28, 28, 75)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 28, 28, 50)        33800     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_78 (MaxPooling (None, 10, 10, 50)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 10, 10, 50)        200       \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 10, 10, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_79 (MaxPooling (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_80 (MaxPooling (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 450)               0         \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 450)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 24)                10824     \n",
      "=================================================================\n",
      "Total params: 136,549.0\n",
      "Trainable params: 136,149.0\n",
      "Non-trainable params: 400.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.keras.api.keras.models import Sequential\n",
    "from tensorflow.contrib.keras.api.keras.layers import (\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    ")\n",
    "model = Sequential()\n",
    "model.add(Conv2D(100, (3, 3), strides=1, padding=\"same\", activation=\"relu\", \n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(75, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(50, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D((2, 2), strides=3, padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(MaxPool2D((3, 3), strides=2, padding=\"same\"))\n",
    "model.add(Conv2D(50, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=num_classes, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarizing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_97 (Conv2D)           (None, 28, 28, 100)       1000      \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 28, 28, 100)       400       \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 28, 28, 75)        67575     \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 28, 28, 75)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 28, 28, 50)        33800     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_78 (MaxPooling (None, 10, 10, 50)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 10, 10, 50)        200       \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 10, 10, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_79 (MaxPooling (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 5, 5, 50)          22550     \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 5, 5, 50)          200       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_80 (MaxPooling (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 450)               0         \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 450)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 24)                10824     \n",
      "=================================================================\n",
      "Total params: 136,549.0\n",
      "Trainable params: 136,149.0\n",
      "Non-trainable params: 400.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"],optimizer='adam')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27455 samples, validate on 7172 samples\n",
      "Epoch 1/25\n",
      "27455/27455 [==============================] - 21s - loss: 0.0066 - acc: 0.9978 - val_loss: 0.0728 - val_acc: 0.9734\n",
      "Epoch 2/25\n",
      "27455/27455 [==============================] - 20s - loss: 0.0073 - acc: 0.9976 - val_loss: 0.0982 - val_acc: 0.9742\n",
      "Epoch 3/25\n",
      "27455/27455 [==============================] - 20s - loss: 0.0042 - acc: 0.9988 - val_loss: 0.0609 - val_acc: 0.9725\n",
      "Epoch 4/25\n",
      "27455/27455 [==============================] - 21s - loss: 0.0049 - acc: 0.9985 - val_loss: 0.0581 - val_acc: 0.9851\n",
      "Epoch 5/25\n",
      "27455/27455 [==============================] - 21s - loss: 0.0041 - acc: 0.9986 - val_loss: 0.0574 - val_acc: 0.9798\n",
      "Epoch 6/25\n",
      "27455/27455 [==============================] - 21s - loss: 0.0051 - acc: 0.9985 - val_loss: 0.1212 - val_acc: 0.9605\n",
      "Epoch 7/25\n",
      "27455/27455 [==============================] - 21s - loss: 0.0050 - acc: 0.9982 - val_loss: 0.1027 - val_acc: 0.9696\n",
      "Epoch 8/25\n",
      "27455/27455 [==============================] - 21s - loss: 0.0063 - acc: 0.9980 - val_loss: 0.0839 - val_acc: 0.9668\n",
      "Epoch 9/25\n",
      "27455/27455 [==============================] - 20s - loss: 0.0043 - acc: 0.9986 - val_loss: 0.0326 - val_acc: 0.9926\n",
      "Epoch 10/25\n",
      "27455/27455 [==============================] - 21s - loss: 0.0081 - acc: 0.9974 - val_loss: 0.1157 - val_acc: 0.9746\n",
      "Epoch 11/25\n",
      "27455/27455 [==============================] - 20s - loss: 0.0034 - acc: 0.9989 - val_loss: 0.0681 - val_acc: 0.9819\n",
      "Epoch 12/25\n",
      "27455/27455 [==============================] - 21s - loss: 0.0032 - acc: 0.9989 - val_loss: 0.0823 - val_acc: 0.9813\n",
      "Epoch 13/25\n",
      "27455/27455 [==============================] - 21s - loss: 0.0030 - acc: 0.9989 - val_loss: 0.0609 - val_acc: 0.9834\n",
      "Epoch 14/25\n",
      "27455/27455 [==============================] - 21s - loss: 0.0040 - acc: 0.9985 - val_loss: 0.1394 - val_acc: 0.9625\n",
      "Epoch 15/25\n",
      "27455/27455 [==============================] - 21s - loss: 0.0023 - acc: 0.9991 - val_loss: 0.0650 - val_acc: 0.9856\n",
      "Epoch 16/25\n",
      "27455/27455 [==============================] - 21s - loss: 0.0046 - acc: 0.9985 - val_loss: 0.0601 - val_acc: 0.9792\n",
      "Epoch 17/25\n",
      "27455/27455 [==============================] - 21s - loss: 0.0052 - acc: 0.9983 - val_loss: 0.0569 - val_acc: 0.9863\n",
      "Epoch 18/25\n",
      "27455/27455 [==============================] - 22s - loss: 0.0046 - acc: 0.9984 - val_loss: 0.0513 - val_acc: 0.9891\n",
      "Epoch 19/25\n",
      "27455/27455 [==============================] - 21s - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0828 - val_acc: 0.9718\n",
      "Epoch 20/25\n",
      "27455/27455 [==============================] - 22s - loss: 0.0032 - acc: 0.9989 - val_loss: 0.0888 - val_acc: 0.9835\n",
      "Epoch 21/25\n",
      "27455/27455 [==============================] - 21s - loss: 0.0023 - acc: 0.9992 - val_loss: 0.1350 - val_acc: 0.9516\n",
      "Epoch 22/25\n",
      "27455/27455 [==============================] - 21s - loss: 0.0070 - acc: 0.9977 - val_loss: 0.0912 - val_acc: 0.9808\n",
      "Epoch 23/25\n",
      "27455/27455 [==============================] - 21s - loss: 0.0093 - acc: 0.9966 - val_loss: 0.0864 - val_acc: 0.9785\n",
      "Epoch 24/25\n",
      "27455/27455 [==============================] - 20s - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0973 - val_acc: 0.9706\n",
      "Epoch 25/25\n",
      "27455/27455 [==============================] - 20s - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0855 - val_acc: 0.9844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.keras.python.keras.callbacks.History at 0x1ee04880240>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=25, verbose=1, validation_data=(x_valid, y_valid),batch_size = 128)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training accuracy is very high, and the validation accuracy has improved as well. This is a great result, as all we had to do was swap in a new model.\n",
    "But the validation accuracy jumping around. This is an indication that our model is still not generalizing perfectly. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e8fca10fe45767dfb0a46ab9250db575916ef435c8f35fb8d3602399b983ae86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
